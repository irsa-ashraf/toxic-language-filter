{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for Toxic Language Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download(\"all\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_SENT_LENGTH = 200\n",
    "EMBED_DIM = 300\n",
    "\n",
    "device = cuda."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1b7fe21f6b20f176</td>\n",
       "      <td>The Wack Pack \\n\\nYou're fucking insane and dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2b77b61ee27ab6fb</td>\n",
       "      <td>Not according to Wikipedia policy. With respec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>626d12d910b34c40</td>\n",
       "      <td>You just revert my and a lot of peoples work, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2ed8095b9ee464b0</td>\n",
       "      <td>Frank O'Hara, Anti-Beat? \\nSeriously, dude, yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86f8607fd0572b9f</td>\n",
       "      <td>\"\\n\\nreverting\\nUser:Baristarim decides that t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  1b7fe21f6b20f176  The Wack Pack \\n\\nYou're fucking insane and dr...      1\n",
       "1  2b77b61ee27ab6fb  Not according to Wikipedia policy. With respec...      0\n",
       "2  626d12d910b34c40  You just revert my and a lot of peoples work, ...      1\n",
       "3  2ed8095b9ee464b0  Frank O'Hara, Anti-Beat? \\nSeriously, dude, yo...      0\n",
       "4  86f8607fd0572b9f  \"\\n\\nreverting\\nUser:Baristarim decides that t...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load balanced data\n",
    "data = pd.read_csv(\"../data/balanced_data.csv\")\n",
    "data = data[data[\"word_count\"] <= MAX_SENT_LENGTH]\n",
    "data = data.reset_index()\n",
    "data = data[[\"comment_text\", \"toxic\"]]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28929"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPU set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-trained text embedding set up "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GloVe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2044,  0.1643,  0.0418,  ..., -0.3401, -0.0771, -0.0841],\n",
      "        [-0.1749,  0.2296,  0.2492,  ..., -0.2413, -0.4040,  0.0547],\n",
      "        [-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "        [ 0.2887, -0.5307, -0.0883,  ..., -0.2334, -0.2379,  0.3161]])\n",
      "torch.Size([4, 300])\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "VECTOR_CACHE_DIR = './glove/.vector_cache'\n",
    "\n",
    "glove = GloVe(name='6B', cache = VECTOR_CACHE_DIR)\n",
    "\n",
    "print(glove.get_vecs_by_tokens([\"this\", \"is\", \"a\", \"comment\"]))\n",
    "print(glove.get_vecs_by_tokens([\"this\", \"is\", \"a\", \"comment\"]).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize word and map with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def process_input(batch):\n",
    "    '''\n",
    "    Tokenize a batch of texts:\n",
    "        - convert sentence to lower case\n",
    "        - tokenize word with package `word_tokenize`\n",
    "        - add paddings to MAX_SENT_LENGTH\n",
    "        - convert tokenized sentence into GloVe embeddings\n",
    "        - return a numpy array of input vectors \n",
    "    '''\n",
    "\n",
    "    # set up containers\n",
    "    y = torch.zeros(BATCH_SIZE)\n",
    "    x = torch.zeros(BATCH_SIZE, MAX_SENT_LENGTH, EMBED_DIM)\n",
    "    \n",
    "    for i, (sent, label) in enumerate(batch):\n",
    "\n",
    "        sent = sent.lower()\n",
    "        tokenized_sent = word_tokenize(sent)\n",
    "\n",
    "        # perform padding or truncate\n",
    "        if len(tokenized_sent) < MAX_SENT_LENGTH:\n",
    "            tokenized_sent += ['<pad>'] * (MAX_SENT_LENGTH - len(tokenized_sent))\n",
    "        else:\n",
    "            tokenized_sent = tokenized_sent[:MAX_SENT_LENGTH]\n",
    "\n",
    "        vecs = glove.get_vecs_by_tokens(tokenized_sent)\n",
    "\n",
    "        x[i] = vecs\n",
    "        y[i] = label\n",
    "    \n",
    "    y = y.type(torch.LongTensor)\n",
    "\n",
    "    return x, y \n",
    "\n",
    "# def process_input(batch):\n",
    "#     '''\n",
    "#     Tokenize a batch of texts:\n",
    "#         - convert sentence to lower case\n",
    "#         - tokenize word with package `word_tokenize`\n",
    "#         - add paddings to MAX_SENT_LENGTH\n",
    "#         - convert tokenized sentence into GloVe embeddings\n",
    "#         - return a numpy array of input vectors \n",
    "#     '''\n",
    "\n",
    "#     # set up containers\n",
    "#     y = torch.zeros(BATCH_SIZE)\n",
    "#     x = torch.zeros(BATCH_SIZE, MAX_SENT_LENGTH)\n",
    "    \n",
    "#     for i, (sent, label) in enumerate(batch):\n",
    "\n",
    "#         sent = sent.lower()\n",
    "#         tokenized_sent = word_tokenize(sent)\n",
    "\n",
    "#         # perform padding or truncate\n",
    "#         if len(tokenized_sent) < MAX_SENT_LENGTH:\n",
    "#             tokenized_sent += ['<pad>'] * (MAX_SENT_LENGTH - len(tokenized_sent))\n",
    "#         else:\n",
    "#             tokenized_sent = tokenized_sent[:MAX_SENT_LENGTH]\n",
    "\n",
    "#         x[i] = torch.tensor(tokenized_sent)\n",
    "#         y[i] = label\n",
    "\n",
    "#     return x, y "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custome Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized dataset: \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, df):\n",
    "        # self.is_test = is_test\n",
    "        self.dataframe = df\n",
    "        self.label_name = df.columns[-1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataframe.iloc[idx]['comment_text']\n",
    "        label = self.dataframe.iloc[idx][self.label_name]\n",
    "        return text, label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data: train 70%, validation 20%, test 10%\n",
    "\n",
    "train_df, rest_df = train_test_split(data, test_size=0.3, random_state=1)\n",
    "val_df, test_df = train_test_split(rest_df, test_size=0.33, random_state=1)\n",
    "\n",
    "# convert dataframes into cusmotized datasets\n",
    "\n",
    "train_data = CustomDataset(train_df)\n",
    "val_data = CustomDataset(val_df)\n",
    "test_data = CustomDataset(test_df)\n",
    "\n",
    "# create dataloader\n",
    "# droplast: if last batch is incomplete, we drop the last batch\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, \n",
    "                              collate_fn=process_input, drop_last=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, \n",
    "                            collate_fn=process_input, drop_last=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, \n",
    "                             collate_fn=process_input, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (text, label) in enumerate(test_dataloader):\n",
    "#     print(i)\n",
    "#     print(text)\n",
    "#     print(label)\n",
    "\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN Version 0 </p>\n",
    "\n",
    "For the first model, we are testing the following parameters\n",
    "\n",
    "|Description         |Values           |\n",
    "|:------------------:|:---------------:|\n",
    "|input word vectors  |GloVe            |\n",
    "|embedding size      |300              |\n",
    "|filter sizes        |(2, 3, 4, 5)     |\n",
    "|num filters         |(64, 64, 64, 64) |\n",
    "|activation          |ReLU             |\n",
    "|pooling             |1-max pooling    |\n",
    "|dropout rate        |0.5              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_NLP(nn.Module):\n",
    "    '''\n",
    "    An 1D Convulational Neural Network for Sentence Classification.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, filter_sizes=[2, 3, 4, 5], num_filters=[64, 64, 64, 64], \n",
    "                 embed_dim=EMBED_DIM, num_classes=2, dropout=0.5):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            pretrained_embedding (torch.Tensor): size (max_sent_length, embed_dim)\n",
    "            freeze_embedding (bool): set to False by default\n",
    "            max_sent_length (int): longest sentence allowed\n",
    "            embed_dim (int): dimension of word vectors, by default: 300\n",
    "            filter_sizes (List[int]): list of filter sizes, by default: [2, 3, 4, 5]\n",
    "            num_filters (List[int]): list of number of filters, [64] * 4\n",
    "            n_classes (int): number of classes, by default: 2\n",
    "            dropout (float): Dropout rate, by default: 0.5\n",
    "        \"\"\"\n",
    "\n",
    "        super(CNN_NLP, self).__init__()\n",
    "\n",
    "        # # Embedding layer\n",
    "        # if pretrained_embedding is not None:\n",
    "        #     self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
    "        #     self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n",
    "        #                                                   freeze=freeze_embedding)\n",
    "        # else:\n",
    "        #     self.embed_dim = embed_dim\n",
    "        #     self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "        #                                   embedding_dim=self.embed_dim,\n",
    "        #                                   padding_idx=0,\n",
    "        #                                   max_norm=5.0)\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Conv Network\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.embed_dim, \n",
    "                      out_channels=num_filters[i], \n",
    "                      kernel_size=filter_sizes[i])\n",
    "            for i in range(len(filter_sizes))])\n",
    "        \n",
    "        # Fully-connected layer and Dropout\n",
    "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Perform a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): tensor of batch of sentences with shape\n",
    "            (batch_size, max_sent_length, embedding_dim)\n",
    "\n",
    "        Returns:\n",
    "            logits (torch.Tensor): Output logits with shape (batch_size,\n",
    "            n_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        # permute input to match the shape requirement of `nn.Conv1d`.\n",
    "        # x_reshaped shape: (BATCH_SIZE, EMBED_DIM, MAX_SENT_LENGTH)\n",
    "        x_reshaped = input.permute(0, 2, 1)\n",
    "\n",
    "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
    "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
    "\n",
    "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
    "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2]) for x_conv in x_conv_list]\n",
    "        \n",
    "        # Concatenate x_pool_list to feed the fully connected layer.\n",
    "        # Output shape: (b, sum(num_filters))\n",
    "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list], dim=1)\n",
    "        \n",
    "        # Compute logits. Output shape: (b, n_classes)\n",
    "        logits = self.fc(self.dropout(x_fc))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Check for GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "def initilize_model(embed_dim=EMBED_DIM, filter_sizes=[2, 3, 4, 5], num_filters=[64, 64, 64, 64], \n",
    "                    num_classes=2, dropout=0.5, learning_rate=0.01):\n",
    "\n",
    "    '''\n",
    "    Instantiate a CNN model and an optimizer.\n",
    "    '''\n",
    "\n",
    "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
    "    num_filters need to be of the same length.\"\n",
    "\n",
    "    cnn_model = CNN_NLP(filter_sizes=filter_sizes,\n",
    "                        num_filters=num_filters,\n",
    "                        embed_dim=embed_dim,\n",
    "                        num_classes=num_classes,\n",
    "                        dropout=dropout)\n",
    "    \n",
    "    cnn_model.to(device)\n",
    "\n",
    "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               rho=0.95)\n",
    "\n",
    "    return cnn_model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    '''\n",
    "    Set seed for reproducibility.\n",
    "    '''\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "\n",
    "def evaluate_val(model, val_dataloader):\n",
    "    '''\n",
    "    After the completion of each training epoch, \n",
    "    measure the model's performance on our validation set.\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "\n",
    "        b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input)\n",
    "\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataloader, val_dataloader, epochs=10, check_train_loss=False):\n",
    "    '''\n",
    "    Train the CNN model.\n",
    "    '''\n",
    "    \n",
    "    best_model = None\n",
    "    val_accuracies = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    print(\"Start training...\\n\")\n",
    "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        t0_epoch = time.time()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        # ============= Training =============\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # forward and compute loss\n",
    "            b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "            logits = model(b_input)\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "        # ============= Evaluation =============\n",
    "\n",
    "        val_loss, val_accuracy = evaluate_val(model, val_dataloader)\n",
    "\n",
    "        if not best_model:\n",
    "            best_model = model\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_model = model\n",
    "\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "        print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            \n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "\n",
    "    if check_train_loss:\n",
    "        return best_model, val_accuracies, val_losses, train_losses, \n",
    "    return best_model, val_accuracies, val_losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_model(model, test_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy = []\n",
    "    test_loss = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input)\n",
    "\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        test_loss.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        test_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    test_loss = np.mean(test_loss)\n",
    "    test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "# def test_model(model, test_dataloader, compare_data=False):\n",
    "#     '''\n",
    "#     test the model on test data, return a DataFrame \n",
    "#     of ID, prediction label and actural label\n",
    "#     '''\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "#     predictions = []\n",
    "#     labels = []\n",
    "#     losses = []\n",
    "#     # ids = []\n",
    "#     # ids.to(device)\n",
    "#     # predictions.to(device)\n",
    "#     # labels.to(device)\n",
    "\n",
    "#     for i, batch in enumerate(test_dataloader):\n",
    "\n",
    "#         b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             logits = model(b_input)\n",
    "\n",
    "#         loss = loss_fn(logits, b_labels)\n",
    "#         losses.append(loss.item())\n",
    "#         preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "#         # ids.extend(list(b_ids))\n",
    "#         labels.extend(list(b_labels))\n",
    "#         predictions.extend(list(preds))\n",
    "\n",
    "#         if i % 200 == 0 and i != 0:\n",
    "#             print(\"After {} batches, the loss is {}\".format(i, loss))\n",
    "\n",
    "\n",
    "    # test_loss = np.mean(losses)\n",
    "\n",
    "    # if we need to check predictions and labels, \n",
    "    # return test_loss and a pred-label dataframe\n",
    "\n",
    "    # if compare_data:\n",
    "    #     performance = {\"prediction\": predictions,\n",
    "    #                    \"label\": labels}\n",
    "    #     return test_loss, pd.DataFrame(performance)\n",
    "    \n",
    "    # if we only need to check model performance, \n",
    "    # return test_loss and confusion matrix\n",
    "    \n",
    "    # else:\n",
    "    #     cm = confusion_matrix(labels, predictions)\n",
    "    #     return test_loss, cm\n",
    "\n",
    "def eval_cm(cm):\n",
    "    '''\n",
    "    ravel a comfusion matrix, and return \n",
    "    accuracy, precision, recall, f1 \n",
    "    '''\n",
    "    tn, fp, fn, tp = cm.ravel() \n",
    "    accu = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "    eval = {\"Accuracy\": [accu],\n",
    "            \"Precision\": [prec],\n",
    "            \"Recall\": [recall],\n",
    "            \"F1\": [f1]}\n",
    "    \n",
    "    return pd.DataFrame(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, test_dataloader):\n",
    "    '''\n",
    "    After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input, _ = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input)\n",
    "        b_pred = torch.argmax(logits, dim=1).flatten()\n",
    "        for v in b_pred:\n",
    "            preds.append(int(v))\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_tag(row):\n",
    "    '''\n",
    "    helper function to get 4 different tags based on \n",
    "    the predicted value and the actual value: \n",
    "    \"TP\", \"TN\", \"FP\", \"FN\" \n",
    "\n",
    "    the labels are binary, so we only have 4 conditions:\n",
    "        label(1) * pred(1) = 1  ---> \"TP\"\n",
    "        label(0) - pred(0) = 0  ---> \"TN\" (excluding previous condition)\n",
    "        label(0) - pred(1) = -1 ---> \"FP\" (excluding previous conditions)\n",
    "        label(1) - pred(0) = 1  ---> \"FN\" (excluding previous conditions)\n",
    "    '''\n",
    "    \n",
    "    pred = row[\"pred\"]\n",
    "    label = row[\"label\"]\n",
    "\n",
    "    if label * pred == 1:\n",
    "        return 'TP'\n",
    "    elif label - pred == 0:\n",
    "        return 'TN'\n",
    "    elif label - pred == -1:\n",
    "        return 'FP'\n",
    "    elif label - pred == 1:\n",
    "        return 'FN'\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "\n",
    "def tag_performances(preds, df):\n",
    "    '''\n",
    "    take predictions from model on test_df, tag \n",
    "    cases of prediction: \"TP\", \"TN\", \"FP\", \"FN\" \n",
    "    preds: [list] \n",
    "    test_data: [DataFrame]\n",
    "    '''\n",
    "\n",
    "    N = len(preds)\n",
    "\n",
    "    assert N == len(df) - (len(df) % 16), \\\n",
    "    \"AssertionError: number of predictions should equal to the number of examples\"\n",
    "\n",
    "    # change the last column name\n",
    "    last_column_name = df.columns[-1]\n",
    "    df = df.rename(columns={last_column_name: \"label\"})\n",
    "\n",
    "    # add new column for model predictions\n",
    "    df = df[: N]\n",
    "    df[\"pred\"] = preds\n",
    "\n",
    "    # tag \"TP\", \"TN\", \"FP\", \"FN\" for each pair\n",
    "    df['tag'] = df.apply(get_tag, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 1 `best_model_0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   0.528128   |  0.399364  |   85.30   |  226.91  \n",
      "   2    |   0.363661   |  0.317377  |   87.72   |  229.22  \n",
      "   3    |   0.311483   |  0.287456  |   88.62   |  228.62  \n",
      "   4    |   0.283751   |  0.271325  |   89.22   |  226.00  \n",
      "   5    |   0.268967   |  0.261541  |   89.65   |  212.46  \n",
      "   6    |   0.258044   |  0.254281  |   89.94   |  199.25  \n",
      "   7    |   0.248379   |  0.248118  |   90.05   |  203.42  \n",
      "   8    |   0.240250   |  0.243319  |   90.29   |  205.28  \n",
      "   9    |   0.232290   |  0.239913  |   90.67   |  205.68  \n",
      "  10    |   0.225141   |  0.236111  |   90.58   |  236.86  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 90.67%.\n"
     ]
    }
   ],
   "source": [
    "# train model with 10 epocks\n",
    "cnn_model, optimizer = initilize_model()\n",
    "best_model_0, val_accuracies_0, val_losses_0 = train(cnn_model, optimizer, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85.2961432506887,\n",
       " 87.72382920110194,\n",
       " 88.61914600550965,\n",
       " 89.22176308539945,\n",
       " 89.65220385674931,\n",
       " 89.94490358126721,\n",
       " 90.04820936639119,\n",
       " 90.2892561983471,\n",
       " 90.66804407713498,\n",
       " 90.58195592286502]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation accuracy of `best_model_0` (10 epochs)')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [x+1 for x in range(10)]\n",
    "\n",
    "plt.plot(epochs, val_accuracies_0)\n",
    "\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Validation accuracy of `best_model_0` (10 epochs)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Report:** </p>\n",
    "\n",
    "```python\n",
    "\n",
    "(CNN_NLP(\n",
    "   (conv1d_list): ModuleList(\n",
    "     (0): Conv1d(300, 64, kernel_size=(2,), stride=(1,))\n",
    "     (1): Conv1d(300, 64, kernel_size=(3,), stride=(1,))\n",
    "     (2): Conv1d(300, 64, kernel_size=(4,), stride=(1,))\n",
    "     (3): Conv1d(300, 64, kernel_size=(5,), stride=(1,))\n",
    "   )\n",
    "   (fc): Linear(in_features=256, out_features=2, bias=True)\n",
    "   (dropout): Dropout(p=0.5, inplace=False)\n",
    " )\n",
    "```\n",
    "\n",
    "**Training performance:**\n",
    "\n",
    "| Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
    "|:------:|:------------:|:----------:|:---------:|:-------:|\n",
    "|   1    |   0.515071   |  0.387810  |   85.50   |  222.95 | \n",
    "|   2    |   0.357476   |  0.314949  |   87.84   |  214.95 |\n",
    "|   3    |   0.307458   |  0.286911  |   88.58   |  217.30 |\n",
    "|   4    |   0.283827   |  0.271694  |   89.29   |  212.41 |\n",
    "|   5    |   0.269294   |  0.261957  |   89.29   |  217.79 |\n",
    "|   6    |   0.257123   |  0.254316  |   89.50   |  238.22 |\n",
    "|   7    |   0.247575   |  0.248300  |   89.76   |  223.09 |\n",
    "|   8    |   0.239426   |  0.243885  |   89.81   |  216.53 |\n",
    "|   9    |   0.233904   |  0.239794  |   90.08   |  210.70 |\n",
    "|  10    |   0.227885   |  0.236559  |   90.17   |  221.15 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see some of the false prediction results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_predictions(best_model_0, test_dataloader)\n",
    "results_cnn_0 = tag_performances(preds, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>12a1805ef86d1267</td>\n",
       "      <td>He is not gay in Rugrats, but on the internet,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>9e25d9bb1e79ede6</td>\n",
       "      <td>Unfairly blocked as Mattythewhite got the hump...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28361</th>\n",
       "      <td>a3b68ab21bbd0439</td>\n",
       "      <td>WHY DID THEY DELETED IT BECAUSE I MADE IT THAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24142</th>\n",
       "      <td>13d34f8041fbec39</td>\n",
       "      <td>Cease and defuck\\nYour work is a fuckability. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>24d25ca2fe7e07ea</td>\n",
       "      <td>User, YOU ARE MISTAKEN.  THE CAPITAL HILL BLUE...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text   \n",
       "1841   12a1805ef86d1267  He is not gay in Rugrats, but on the internet,...  \\\n",
       "1154   9e25d9bb1e79ede6  Unfairly blocked as Mattythewhite got the hump...   \n",
       "28361  a3b68ab21bbd0439  WHY DID THEY DELETED IT BECAUSE I MADE IT THAT...   \n",
       "24142  13d34f8041fbec39  Cease and defuck\\nYour work is a fuckability. ...   \n",
       "19656  24d25ca2fe7e07ea  User, YOU ARE MISTAKEN.  THE CAPITAL HILL BLUE...   \n",
       "\n",
       "       label  pred tag  \n",
       "1841       1     0  FN  \n",
       "1154       1     0  FN  \n",
       "28361      1     0  FN  \n",
       "24142      1     0  FN  \n",
       "19656      1     0  FN  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the false negative predictions\n",
    "false_neg_cnn_0 = results_cnn_0[results_cnn_0[\"tag\"] == \"FN\"]\n",
    "false_neg_cnn_0.to_csv(\"FN_model0.csv\")\n",
    "false_neg_cnn_0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19916</th>\n",
       "      <td>7ab55f5165ed9291</td>\n",
       "      <td>The failure of Fagreterion \\n\\nFagreterion can...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>0be7965b23078261</td>\n",
       "      <td>\"Just face the truth: you can't escape it!==\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>7f0f1a7286ecbc51</td>\n",
       "      <td>hayyyyyyyyy \\n\\nyeah this karoolzzz hay k hayy...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26972</th>\n",
       "      <td>96b055eca6cc56b0</td>\n",
       "      <td>a debate to see why he was so virulently anti-...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>f97e67368b5eee9d</td>\n",
       "      <td>Well, I seemed to be able to change it just fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text   \n",
       "19916  7ab55f5165ed9291  The failure of Fagreterion \\n\\nFagreterion can...  \\\n",
       "6032   0be7965b23078261  \"Just face the truth: you can't escape it!==\\n...   \n",
       "7878   7f0f1a7286ecbc51  hayyyyyyyyy \\n\\nyeah this karoolzzz hay k hayy...   \n",
       "26972  96b055eca6cc56b0  a debate to see why he was so virulently anti-...   \n",
       "5618   f97e67368b5eee9d  Well, I seemed to be able to change it just fi...   \n",
       "\n",
       "       label  pred tag  \n",
       "19916      0     1  FP  \n",
       "6032       0     1  FP  \n",
       "7878       0     1  FP  \n",
       "26972      0     1  FP  \n",
       "5618       0     1  FP  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the false positive predictions\n",
    "false_pos_cnn_0 = results_cnn_0[results_cnn_0[\"tag\"] == \"FP\"]\n",
    "false_pos_cnn_0.to_csv(\"FP_model0.csv\")\n",
    "false_pos_cnn_0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in false_neg_cnn_0.iterrows():\n",
    "#     id = row[\"id\"]\n",
    "#     sent = row[\"comment_text\"]\n",
    "#     print(\"id:\")\n",
    "#     print(id)\n",
    "#     print(\"comment: \")\n",
    "#     print(sent)\n",
    "#     print(\"============\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same model with 30 epochs to show overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with 30 epochs\n",
    "cnn_model, optimizer = initilize_model()\n",
    "best_model_0_30, val_accuracies_0_30, val_losses_0_30, train_losses_0_30 = \\\n",
    "    train(cnn_model, optimizer, train_dataloader, val_dataloader, epochs=30, check_train_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [x+1 for x in range(10)]\n",
    "\n",
    "plt.plot(epochs, val_accuracies_0)\n",
    "\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Validation accuracy of `best_model_0` (10 epochs)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # pickle a model\n",
    "# with open('best_model_0.pkl', 'wb') as file:\n",
    "#     pickle.dump(best_model_0, file)\n",
    "\n",
    "# # load the pickled model\n",
    "# with open('best_model_0.pkl', 'rb') as file:\n",
    "#     best_model_0 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_model(model, test_dataloader, compare_data=False):\n",
    "    '''\n",
    "    test the model on test data, return a DataFrame \n",
    "    of ID, prediction label and actural label\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    # ids = []\n",
    "    # ids.to(device)\n",
    "    # predictions.to(device)\n",
    "    # labels.to(device)\n",
    "\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "\n",
    "        b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input)\n",
    "\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # ids.extend(list(b_ids))\n",
    "        labels.extend(list(b_labels))\n",
    "        predictions.extend(list(preds))\n",
    "\n",
    "        if i % 200 == 0 and i != 0:\n",
    "            print(\"After {} batches, the loss is {}\".format(i, loss))\n",
    "\n",
    "\n",
    "    test_loss = np.mean(losses)\n",
    "\n",
    "    # if we need to check predictions and labels, \n",
    "    # return test_loss and a pred-label dataframe\n",
    "\n",
    "    if compare_data:\n",
    "        performance = {\"prediction\": predictions,\n",
    "                       \"label\": labels}\n",
    "        return test_loss, pd.DataFrame(performance)\n",
    "    \n",
    "    # if we only need to check model performance, \n",
    "    # return test_loss and confusion matrix\n",
    "    \n",
    "    else:\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        return test_loss, cm\n",
    "\n",
    "def eval_cm(cm):\n",
    "    '''\n",
    "    ravel a comfusion matrix, and return \n",
    "    accuracy, precision, recall, f1 \n",
    "    '''\n",
    "    tn, fp, fn, tp = cm.ravel() \n",
    "    accu = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "    eval = {\"Accuracy\": [accu],\n",
    "            \"Precision\": [prec],\n",
    "            \"Recall\": [recall],\n",
    "            \"F1\": [f1]}\n",
    "    \n",
    "    return pd.DataFrame(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, cm = test_model(best_model_0, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy = []\n",
    "    test_loss = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input)\n",
    "\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        test_loss.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        test_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    test_loss = np.mean(test_loss)\n",
    "    test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open('best_model_og.pkl', 'rb') as file:\n",
    "    best_model_og = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capp30255",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
